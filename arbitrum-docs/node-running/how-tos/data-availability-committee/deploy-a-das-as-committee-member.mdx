---
title: 'How to configure a Data Availability Committee: deploy a Data Availability Server (DAS) as a committee member'
description: This how-to will help you deploy a Data Availability Server (DAS) as a committee member
author: jose-franco
sidebar_label: Deploy a committee member DAS
sidebar_position: 2
content-type: how-to
---

import PublicPreviewBannerPartial from '../../../partials/_public-preview-banner-partial.md';

<PublicPreviewBannerPartial />

<p>
  <a data-quicklook-from="arbitrum-anytrust-protocol">AnyTrust</a> chains rely on an external Data
  Availability Committee (DAC) to store data and provide it on demand instead of using the{' '}
  <a data-quicklook-from="parent-chain">parent chain</a> as the Data Availability (DA) layer. The
  members of the DAC run a Data Availability Server (DAS) to handle these operations.
</p>

In this how-to you'll learn how to deploy a DAS as a committee member and enable an RPC interface to store batches received from the sequencer. We'll also describe how to enable an optional REST interface to respond to requests of stored information. For more information related to configuring a DAC, please see the [Introduction](./introduction.mdx).

You should be familiarized with how the AnyTrust protocol works and what's the role of the DAC in the protocol. You can find more information about the AnyTrust protocol in [Inside AnyTrust](/inside-anytrust.mdx). It is also recommended to be familiarized with [Kubernetes](https://kubernetes.io/) as the examples on this guide are based on that software.

import HowDASWorkContent from './partials/_1-how-das-work-content.mdx';

## How does a Data Availability Server work?

<HowDASWorkContent />

import DASConfigurationOptionsInterfaces from './partials/_2.1-das-configuration-options-interfaces.mdx';
import DASConfigurationOptionsStorage from './partials/_2.2-das-configuration-options-storage.mdx';
import DASConfigurationOptionsCaching from './partials/_2.3-das-configuration-options-caching.mdx';
import DASConfigurationOptionsStateSync from './partials/_2.4-das-configuration-options-state-sync.mdx';

## Configuration options

When setting up a DAS, there are certain options you can configure to suit your infrastructure needs:

### Interfaces available in a DAS

<DASConfigurationOptionsInterfaces />

### Storage options

<DASConfigurationOptionsStorage />

### Caching

<DASConfigurationOptionsCaching />

### State synchronization

<DASConfigurationOptionsStateSync />

## How to deploy the DAS as a committee member

We now start the process of deploying the DAS as a committee member. Remember that you can reach out to us on [Discord](https://discord.gg/arbitrum) if you are having trouble following this process.

### Step 0: Prerequisites

In order to setup your DAS, you'll need the following information:

- The latest Nitro docker image: `@latestNitroNodeImage@`
- An RPC endpoint for the <a data-quicklook-from="parent-chain">parent chain</a>. It is recommended to use a [third-party provider RPC](/node-running/node-providers.mdx#third-party-rpc-providers) or [run your own node](/node-running/how-tos/running-an-orbit-node.mdx) to prevent being rate limited.
- The SequencerInbox contract address in the parent chain.
- If you wish to configure a [REST aggregator for your DAS](#state-synchronization), you'll need the URL where the list of REST endpoints is kept. A REST aggregator is optional when running a committee member DAS.

<!--
In terms of hardware requirements, these are the minimum specs that your infrastructure should comply with to run a stable DAS:

- RAM:
- CPU:

Depending on the storage backend you use for your DAS, you'll need to configure the appropriate infrastructure: for example, an S3 bucket if you choose S3, or a local volume if you choose any of the local backend options. When using a local volume, it is recommended to use …
-->

### Step 1: Set up a persistent volume

First, we'll set up a volume to store the DAS database and the BLS key pair that we generate in the next step.

In k8s, we can use a configuration like this:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: das-server
spec:
accessModes:
  - ReadWriteOnce
resources:
  requests:
  storage: 200Gi
storageClassName: gp2
```

### Step 2: Generate the BLS keypair

Next, we'll generate a BLS key pair. The private key will be used to sign the <a data-quicklook-from="data-availability-certificate">Data Availability Certificates (DACert)</a> when receiving requests to store data, and the public key will be used to prove that the DACert was signed by the DAS.

The BLS key pair must be generated using the `datool keygen` utility. Later, it will be passed to the DAS by file or command line.

When running the key generator, we'll specify the `--dir` parameter with the absolute path to the directory inside the volume to store the keys in. That directory will need to exist before running the tool.

Here's an example of how to use a k8s deployment to run the `datool keygen` utility and store the key on the volume that we created in the previous step and that will be used by the DAS in the next step. After this deployment has run once, the deployment can be torn down and deleted.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
name: das-server
spec:
replicas: 1
selector:
    matchLabels:
    app: das-server
template:
    metadata:
    labels:
        app: das-server
    spec:
    containers:
    - command:
        - bash
        - -c
        - |
        mkdir -p /home/user/data/keys
        /usr/local/bin/datool keygen --dir /home/user/data/keys
        sleep infinity
        image: @latestNitroNodeImage@
        imagePullPolicy: Always
        resources:
        limits:
            cpu: "4"
            memory: 10Gi
        requests:
            cpu: "4"
            memory: 10Gi
        ports:
        - containerPort: 9876
        protocol: TCP
        volumeMounts:
        - mountPath: /home/user/data/
        name: data
    volumes:
    - name: data
        persistentVolumeClaim:
        claimName: das-server
```

### Step 3: Deploy the committee member DAS

To run the committee member DAS, we'll use the `daserver` tool and we'll configure the following parameters:

| Parameter                                   | Description                                                                                                      |
| ------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| --data-availability.parent-chain-node-url   | RPC endpoint of a parent chain node                                                                              |
| --data-availability.sequencer-inbox-address | Address of the SequencerInbox in the parent chain                                                                |
| --data-availability.key.key-dir             | The absolute path to the directory inside the volume to read the BLS key pair ('das_bls.pub' and 'das_bls') from |
| --enable-rpc                                | Enables the HTTP-RPC server listening on --rpc-addr and --rpc-port                                               |
| --rpc-addr                                  | HTTP-RPC server listening interface (default "localhost")                                                        |
| --rpc-port                                  | (Optional) HTTP-RPC server listening port (default 9876)                                                         |
| --log-level                                 | Log level: 1 - ERROR, 2 - WARN, 3 - INFO, 4 - DEBUG, 5 - TRACE (default 3)                                       |

To enable the REST interface (not required on a committee member DAS), you can use the following parameters:

| Parameter     | Description                                                      |
| ------------- | ---------------------------------------------------------------- |
| --enable-rest | Enables the REST server listening on --rest-addr and --rest-port |
| --rest-addr   | REST server listening interface (default "localhost")            |
| --rest-port   | (Optional) REST server listening port (default 9877)             |

To enable caching, you can use the following parameters:

| Parameter                                  | Description                                                             |
| ------------------------------------------ | ----------------------------------------------------------------------- |
| --data-availability.local-cache.enable     | Enables local in-memory caching of sequencer batch data                 |
| --data-availability.local-cache.expiration | Expiration time for in-memory cached sequencer batches (default 1h0m0s) |

To enable the REST aggregator, use the following parameters:

| Parameter                                                                   | Description                                                                                                                                                                                 |
| --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --data-availability.rest-aggregator.enable                                  | Enables retrieval of sequencer batch data from a list of remote REST endpoints                                                                                                              |
| --data-availability.rest-aggregator.online-url-list                         | A URL to a list of URLs of REST DAS endpoints that is checked at startup. This option is additive with the urls option                                                                      |
| --data-availability.rest-aggregator.urls                                    | List of URLs including 'http://' or 'https://' prefixes and port numbers to REST DAS endpoints. This option is additive with the online-url-list option                                     |
| --data-availability.rest-aggregator.sync-to-storage.check-already-exists    | When using a REST aggregator, checks if the data already exists in this DAS's storage. Must be disabled for fast sync with an IPFS backend (default true)                                   |
| --data-availability.rest-aggregator.sync-to-storage.eager                   | When using a REST aggregator, eagerly syncs batch data to this DAS's storage from the rest endpoints, using the parent chain as the index of batch data hashes; otherwise only syncs lazily |
| --data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block | When using a REST aggregator that's eagerly syncing, starts indexing forward from this block from the parent chain. Only used if there is no sync state.                                    |
| --data-availability.rest-aggregator.sync-to-storage.retention-period        | When using a REST aggregator, period to retain the synced data (defaults to forever)                                                                                                        |
| --data-availability.rest-aggregator.sync-to-storage.state-dir               | When using a REST aggregator, directory to store the sync state in, i.e. the block number currently synced up to, so that it doesn't sync from scratch each time                            |

Finally, for the storage backends you wish to configure, use the following parameters. toggle between the different options to see all available parameters.

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import S3Parameters from './partials/parameters/_s3-parameters.mdx';
import LocalBadgerDBParameters from './partials/parameters/_local-badger-db-parameters.mdx';
import LocalFilesParameters from './partials/parameters/_local-files-parameters.mdx';
import IPFSParameters from './partials/parameters/_ipfs-parameters.mdx';

<div className="dynamic-content-tabs">
  <Tabs className="tabgroup" defaultValue={null}>
    <TabItem value="s3-bucket" label="AWS S3 bucket">
      <S3Parameters />
    </TabItem>
    <TabItem value="badger-db" label="Local Badger database">
      <LocalBadgerDBParameters />
    </TabItem>
    <TabItem value="local-files" label="Local files">
      <LocalFilesParameters />
    </TabItem>
    <TabItem value="ipfs" label="IPFS">
      <IPFSParameters />
    </TabItem>
  </Tabs>
</div>

Here's an example `daserver` command for a committee member DAS that:

- Enables both interfaces: RPC (required) and REST (optional)
- Enables local cache
- Enables a [REST aggregator](#state-synchronization)
- Enables AWS S3 bucket storage that doesn't discard data after expiring
- Enables local Badger database storage that doesn't discard data after expiring

```bash
daserver
    --data-availability.parent-chain-node-url "<YOUR PARENT CHAIN RPC ENDPOINT>"
    --data-availability.sequencer-inbox-address "<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>"
    --data-availability.key.key-dir /home/user/data/keys
    --enable-rpc
    --rpc-addr '0.0.0.0'
    --log-level 3
    --enable-rest
    --rest-addr '0.0.0.0'
    --data-availability.local-cache.enable
    --data-availability.rest-aggregator.enable
    --data-availability.rest-aggregator.online-url-list "<URL TO LIST OF REST ENDPOINTS>"
    --data-availability.s3-storage.enable
    --data-availability.s3-storage.access-key "<YOUR ACCESS KEY>"
    --data-availability.s3-storage.bucket "<YOUR BUCKET>"
    --data-availability.s3-storage.region "<YOUR REGION>"
    --data-availability.s3-storage.secret-key "<YOUR SECRET KEY>"
    --data-availability.s3-storage.object-prefix "<YOUR OBJECT KEY PREFIX>/"
    --data-availability.local-db-storage.enable
    --data-availability.local-db-storage.data-dir /home/user/data/badgerdb
```

And here's an example of how to use a k8s deployment to run the that command:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
name: das-server
spec:
replicas: 1
selector:
    matchLabels:
    app: das-server
strategy:
    rollingUpdate:
    maxSurge: 0
    maxUnavailable: 50%
    type: RollingUpdate
template:
    metadata:
    labels:
        app: das-server
    spec:
    containers:
    - command:
        - bash
        - -c
        - |
        mkdir -p /home/user/data/badgerdb
        /usr/local/bin/daserver --data-availability.parent-chain-node-url "<YOUR PARENT CHAIN RPC ENDPOINT>" --data-availability.sequencer-inbox-address "<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>" --data-availability.key.key-dir /home/user/data/keys --enable-rpc --rpc-addr '0.0.0.0' --log-level 3 --enable-rest --rest-addr '0.0.0.0' --data-availability.local-cache.enable --data-availability.rest-aggregator.enable --data-availability.rest-aggregator.online-url-list "<URL TO LIST OF REST ENDPOINTS>" --data-availability.s3-storage.enable --data-availability.s3-storage.access-key "<YOUR ACCESS KEY>" --data-availability.s3-storage.bucket "<YOUR BUCKET>" --data-availability.s3-storage.region "<YOUR REGION>" --data-availability.s3-storage.secret-key "<YOUR SECRET KEY>" --data-availability.s3-storage.object-prefix "<YOUR OBJECT KEY PREFIX>/" --data-availability.s3-storage.discard-after-timeout false --data-availability.local-db-storage.enable --data-availability.local-db-storage.data-dir /home/user/data/badgerdb --data-availability.local-db-storage.discard-after-timeout false
        image: @latestNitroNodeImage@
        imagePullPolicy: Always
        resources:
        limits:
            cpu: "4"
            memory: 10Gi
        requests:
            cpu: "4"
            memory: 10Gi
        ports:
        - containerPort: 9876
        hostPort: 9876
        protocol: TCP
        - containerPort: 9877
        hostPort: 9877
        protocol: TCP
        volumeMounts:
        - mountPath: /home/user/data/
        name: data
        readinessProbe:
        failureThreshold: 3
        httpGet:
            path: /health/
            port: 9877
            scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
    volumes:
    - name: data
        persistentVolumeClaim:
        claimName: das-server
```

## Testing the DAS

Once the DAS is running, we can test if everything is working correctly using the following methods.

### Test 1: RPC health check

The RPC interface enabled in the committee member DAS has a health check for the underlying storage that can be invoked by using the RPC method  `das_healthCheck` that returns 200 if the DAS is active.

Example:

```bash
curl -X POST \
     -H 'Content-Type: application/json' \
     -d '{"jsonrpc":"2.0","id":0,"method":"das_healthCheck","params":[]}' \
     <YOUR RPC ENDPOINT>
```

### Test 2: Store and retrieve data

The RPC interface of the DAS validates that requests to store data are signed by the sequencer's ECDSA key, identified via a call to the SequencerInbox contract on the parent chain. It can also be configured to accept store requests signed with another ECDSA key of your choosing. This could be useful for running load tests, canaries, or troubleshooting your own infrastructure.

Using this facility, a load test could be constructed by writing a script to store arbitrary amounts of data at an arbitrary rate; a canary could be constructed to store and retrieve data on some interval.

First, generate an ECDSA key pair with `datool keygen`:

```bash
datool keygen --dir /dir-to-store-the-key-pair/ --ecdsa
```

Then add the following configuration parameter to `daserver`:

```bash
--data-availability.extra-signature-checking-public-key "/dir-to-store-the-key-pair/ecdsa.pub"

OR

--data-availability.extra-signature-checking-public-key "0x<contents of ecdsa.pub>"
```

Now you can use the `datool` utility to send store requests signed with the ECDSA private key:

```bash
datool client rpc store  --url http://localhost:9876 --message "Hello world" --signing-key "/dir-to-store-the-key-pair/ecdsa"

OR

datool client rpc store  --url http://localhost:9876 --message "Hello world" --signing-key "0x<contents of ecdsa>"

```

The above command will output the `Hex Encoded Data Hash` which can then be used to retrieve the data (notice that you must have the REST interface enabled in the DAS):

```bash
datool client rest getbyhash --url http://localhost:9877 --data-hash <0xDataHash>
```

After running that command, the result should be: `Message: Hello world`

The retention period defaults to 24 hours, but can be configured when calling `datool client rpc store` with the parameter `--das-retention-period` and the number of milliseconds for the retention period.

### Test 3 (if the REST interface is enabled): REST health check

The REST interface has a health check on the path `/health` which will return 200 if the underlying storage is working, otherwise 503.

Example:

```bash
curl -I <YOUR REST ENDPOINT>
```

## Security considerations

Keep in mind the following information when running the DAS.

A committee member DAS should strive not to miss any batch of information sent by the sequencer. Although it can use a REST aggregator to fetch missing information from other DAS servers, it should aim to synchronize all received information directly. To facilitate this, avoid placing any load balancing layer before the DAS, enabling it to handle all incoming traffic.

Taking that into account, there's a risk of Denial of Service attacks on those servers if the endpoint for the RPC interface is publicly known. To mitigate this risk, ensure the RPC endpoint's URL is not easily discoverable. It should be known only to the sequencer. Share this information with the chain owner through a private channel to maintain security.

Finally, if you're also running a mirror, there's no need to publicly expose the REST interface of your committee member DAS. Your mirrors can synchronize over your private network using the REST interface from your committee member DAS and other public mirrors.

## What to do next?

Once the DAS is deployed and tested, you'll have to communicate the following information to the chain owner, so they can update the chain parameters and configure the sequencer:

- Public key
- URL of the RPC endpoint (send this information through a private communication channel)
- URL of the REST endpoint (if enabled)

import DASOptionalParameters from './partials/_3-das-optional-parameters.mdx';
import DASMetrics from './partials/_4-das-metrics.mdx';

## Optional parameters

<DASOptionalParameters />

## Metrics

<DASMetrics />
